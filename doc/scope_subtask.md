# Problem Definition and Scope
- **Problem:**
  - Challenge of extracting text precisely from images especially when handwritten mathematical symbols are included
  - Difficulty of translating the text that involves jargon and slang into different languages
- **Application Domain:**
  - Typed and handwritten document scanning and translation
  - Accessibility tools for visually impaired individuals with language barriers
- **Significance:**
  - Automate document processing and translation
  - Enhance global communication
- **Scope:**
  - Developing deep learning text extraction and translation models
  - Evaluate the performance of the system
  - Fine tuning the models to improve accuracy and efficiency
- **Limitations:** Extract and translate text only, excluding other visual contents such as tables and bullet points
- **Assumptions:** Large datasets are available for training and testing the models accurately

---

# Project Subtasks

## 1. Text Extraction from Image
- **Description**:  
  This subtask involves extracting textual content from images using Optical Character Recognition (OCR) or similar technologies. The goal is to accurately identify and retrieve text embedded in images, regardless of font, size, or background complexity.
  
- **Relevance**:  
  Text extraction from images is critical for applications like document digitization, license plate recognition, and assistive technologies for the visually impaired. It serves as the foundation for further processing, such as translation or analysis.

## 2. Text Translation
- **Description**:  
  This subtask focuses on translating extracted text from one language to another. It involves natural language processing (NLP) techniques to ensure accurate and contextually appropriate translations.
  
- **Relevance**:  
  Text translation is essential for breaking language barriers in global communication, enabling cross-lingual information retrieval, and supporting multilingual applications like customer support and content localization.
